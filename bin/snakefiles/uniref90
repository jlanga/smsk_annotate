rule uniref90_split_pep:
    input:
        fai = transdecoder + "transdecoder.pep.fai"
    output:
        expand(
            uniref90 + "chunks/transdecoder_{chunk_id}.tsv",
            chunk_id = [
                '{0:05d}'.format(x) 
                for x in range(0, config["number_of_chunks"]["uniref90_blastp"])
            ]
        )
    params:
        number_of_chunks = config["number_of_chunks"]["uniref90_blastp"]
    log:
        uniref90 + "split_pep.log"
    benchmark:
        uniref90 + "split_pep.json"
    shell:
        "split "
            "--number l/{params.number_of_chunks} "
            "--numeric-suffixes "
            "--suffix-length 5 "
            "--additional-suffix .tsv "
            "{input.fai} "
            "{uniref90}/chunks/transdecoder_ "
        "2> {log}"



rule uniref90_blastp_chunk:
    input:
        pep = transdecoder + "transdecoder.pep",
        fai = transdecoder + "transdecoder.pep.fai",
        chunk = uniref90 + "chunks/transdecoder_{chunk_id}.tsv",
        db = db + "uniref90"
    output:
        tsv = uniref90 + "blastp/transdecoder_{chunk_id}.tsv"
    log:
        uniref90 + "blastp/transdecoder_{chunk_id}.log"
    benchmark:
        uniref90 + "blastp/transdecoder_{chunk_id}.json"
    shell:
        "cut -f 1 {input.chunk} "
        "| xargs samtools faidx {input.pep} "
        "| blastp "
            "-db {input.db} "
            "-max_target_seqs 1 "
            "-outfmt 6 "
            "-evalue 1e-5 "
        "> {output.tsv} " 
        "2> {log}"



rule uniref90_blastp_merge:
    input:
        expand(
            uniref90 + "blastp/transdecoder_{chunk_id}.tsv",
            chunk_id = [
                '{0:05d}'.format(x) 
                for x in range(0, config["number_of_chunks"]["uniref90_blastp"])
            ]
        )
    output:
        tsv = uniref90 + "blastp.tsv"
    log:
        uniref90 + "blastp_merge.log"
    benchmark:
        uniref90 + "blastp_merge.json"
    shell:
        "cat {input} > {output} 2> {log}"