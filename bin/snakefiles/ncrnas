"""
split fasta
| blastn each chunk against Rfam
| join positives into a fasta
| split again
| cmsearch each chunk against Rfam
| join
"""



rule ncrnas_transcriptome_split:
    """
    Split the transcriptome into multiple chunks
    """
    input:
        fai = filtering + "filtered_transcriptome.fasta.fai"
    output:
        expand(
            ncrnas + "blastn/transcriptome_{chunk_id}.tsv",
            chunk_id = [
                '{0:05d}'.format(x) 
                for x in range(0, config["number_of_chunks"]["ncrnas"])
            ])
    params:
        number_of_chunks = config["number_of_chunks"]["ncrnas"]
    log:
        ncrnas + "transcriptome_split.log"
    benchmark:
        ncrnas + "transcriptome_split.json"
    shell:
        "split "
            "--number l/{params.number_of_chunks} "
            "--numeric-suffixes "
            "--suffix-length 5 "
            "--additional-suffix .tsv "
            "{input.fai} "
            "{ncrnas}/blastn/transcriptome_ "
        "2> {log}"



rule ncrnas_candidates_chunk:
    """
    Blastn each chunk into the Rfam blastn database.
    Return a fasta with such sequences
    """
    input:
        fasta = filtering + "filtered_transcriptome.fasta",
        fai = filtering + "filtered_transcriptome.fasta.fai",
        chunk = ncrnas + "blastn/transcriptome_{chunk_id}.tsv",
        db = db + "Rfam"
    output:
        fasta = ncrnas + "cmsearch/candidates_{chunk_id}.fasta"
    log:
        ncrnas + "blastn/blastn_{chunk_id}.log"
    benchmark:
        ncrnas + "blastn/blastn_{chunk_id}.json"
    shell:
        "(cut -f 1 {input.chunk} "
        "| xargs samtools faidx {input.fasta} "
        "| blastn "
            "-db {input.db} "
            "-max_target_seqs 1 "
            "-outfmt 6 "
            "-evalue 1e-5 "
        "| cut -f 1 "
        "| sort -u "
        "| xargs samtools faidx {input.fasta} "
        "> {output.fasta}) "
        "2> {log}"



rule ncrnas_cmsearch_chunk:
    """
    Run cmsearch over each chunk
    """
    input:
        fasta =  ncrnas + "cmsearch/candidates_{chunk_id}.fasta",
        cm = db + "Rfam.cm"
    output:
        tsv = ncrnas + "cmsearch/cmsearch_{chunk_id}.tsv",
        stats = ncrnas + "cmsearch/cmsearch_{chunk_id}.stats"
    log:
        ncrnas + "cmsearch/cmsearch_{chunk_id}.log"
    benchmark:
        ncrnas + "cmsearch/cmsearch_{chunk_id}.json"
    shell: # cmsearch doesn't like empty fastas
        "if [[ -s {input.fasta} ]] ; then "
            "cmsearch "
                "--cut_ga "
                "--tblout {output.tsv} "
                "-o {output.stats} "
                "{input.cm} "
                "{input.fasta} "
            "> {output.tsv} "
            "2> {log} ; "
        "else "
            "touch {output} 2> {log} ; "
        "fi"
        


rule ncrnas_cmsearch_join:
    """
    Join results from cmsearch
    """
    input:
        expand(
            ncrnas + "cmsearch/cmsearch_{chunk_id}.tsv",
            chunk_id = [
                '{0:05d}'.format(x) 
                for x in range(0, config["number_of_chunks"]["ncrnas"])
            ]
        )
    output:
        ncrnas + "cmsearch.tsv"
    log:
        ncrnas + "cmsearch.log"
    benchmark:
        ncrnas + "cmsearch.json"
    shell:
        "cat {input} "
        "| grep -v ^# "
        "> {output} "
        "2> {log}"
